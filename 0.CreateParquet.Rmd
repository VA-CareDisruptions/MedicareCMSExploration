---
title: "index"
author: "Dan Weinberger"
date: '2022-12-28'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(arrow)
library(dplyr)
library(ggplot2)
library(parquetize)
source('./R/schema.R')
 
```

This Rmd file converts CSV files to parquet databases using the arrow package. 

denom files for 2014-2016; after 2016, shifts to MBSF files

```{r}
csv_file_denom <- "T:/denom/den_saf_lds_100_201.csv"

dest_denom <- "T:/parquet/denom/" 

#double()
#string()
#float()
#int32()
#https://www.cms.gov/Research-Statistics-Data-and-Systems/Files-for-Order/LimitedDataSets/Downloads/SAFldsDenomNov2009.pdf

csv_stream_denom <- open_dataset("T:/denom/", format = "csv", schema = sch_denom)
```

Write the data to a parquet database
```{r, eval=F}
write_dataset(csv_stream_denom, dest_denom, format = "parquet", 
              max_rows_per_file=1000000L,
              hive_style = TRUE,
              existing_data_behavior = "overwrite")
```

Do the same for MBSF data

Note on partitioning: 
"Avoid files smaller than 20MB and larger than 2GB.
Avoid partitioning layouts with more than 10,000 distinct partitions."
https://ursalabs.org/arrow-r-nightly/articles/dataset.html

```{r, eval=F}
dest_mbsf <- "T:/parquet/mbsf/" 

csv_stream_mbsf <- open_dataset("T:/mbsf/", format = "csv", schema = sch_dbsf) %>%
  group_by(REFERENCE_YEAR) #ensure chunks are not too large for memory

write_dataset(csv_stream_mbsf, dest_mbsf, format = "parquet", 
               max_rows_per_file = 5e5,
              #max_open_files=20, #default is 900L
              hive_style = TRUE,
              existing_data_behavior = "overwrite")
```

Inpatient base files

```{r}

csv_stream_inp_k <- open_dataset("T:/inp/inp1/basek2016_2021", format = "csv", schema = sch_inp_basek) #%>%
 # dplyr::select(DSYSRTKY,CLAIMNO,THRU_DT, starts_with('ICD'),starts_with('PRCDR'), TOT_CHRG,ADMSN_DT,TYPE_ADM,SRC_ADMS,PCCHGAMT,
             #  GNDR_CD,PTNTSTUS, DOB_DT, RACE_CD,CNTY_CD,STATE_CD,DSCHRGDT, UTIL_DAY, COIN_DAY,PRNCPAL_DGNS_CD)

csv_stream_inp_j <- open_dataset("T:/inp/inp1/basej_2014_2015", format = "csv", schema = sch_inp_basej)  %>%
   rename_with(toupper)

#common_names = intersect(names(csv_stream_inp_k), names(csv_stream_inp_j))

#csv_stream_inp_k <- csv_stream_inp_k%>%
#  dplyr::select(all_of(common_names))

#csv_stream_inp_j <- csv_stream_inp_j%>%
#  dplyr::select(all_of(common_names))

write_dataset(csv_stream_inp_j, "T:/parquet/inp_j/", format = "parquet", 
               max_rows_per_file = 1e5,
              #max_open_files=20, #default is 900L
              hive_style = TRUE,
              existing_data_behavior = "overwrite")

write_dataset(csv_stream_inp_k, "T:/parquet/inp_k_alt/", format = "parquet", 
               max_rows_per_file = 5e6,
           #   max_open_files=20, #default is 900L
              hive_style = TRUE,
              existing_data_behavior = "overwrite")


```


Inpatient charge files

```{r}
csv_stream_inp_k_chg <- open_dataset("T:/inp/inp2/", format = "csv", schema = sch_inp_rev) 

write_dataset(csv_stream_inp_k_chg, "T:/parquet/inp_k_chg/", format = "parquet", 
               max_rows_per_file = 5e6,
           #   max_open_files=20, #default is 900L
              hive_style = TRUE,
              existing_data_behavior = "overwrite")

```




outpatient base files
```{r, eval=F}
csv_stream_outp_k <- open_dataset("T:/out/basek2016_2021/", format = "csv", schema = sch_outp_basek)

# write_dataset(csv_stream_outp_k, "T:/parquet/outp_k/", format = "parquet", 
#                max_rows_per_file = 5e6,
#               hive_style = TRUE,
#               existing_data_behavior = "overwrite")

```

outpatient charge files

```{r}

csv_stream_outp_charge <- open_dataset("T:/out/charge_k", format = "csv", schema = sch_outp_rev) #%>%
 # dplyr::select(DSYSRTKY,CLAIMNO,THRU_DT,CLM_TYPE,REV_CNTR)

write_dataset(csv_stream_outp_charge, "T:/parquet/outp_k_charge/" , format = "parquet", 
               max_rows_per_file = 5e6,
              hive_style = TRUE,
              existing_data_behavior = "overwrite")
```

Skilled nursing

```{r}
dest_snf <- "T:/parquet/snf/" 

csv_stream_snf <- open_dataset("T:/snf/claimsk2016_2021/", format = "csv", schema = sch_snf_basek) 

write_dataset(csv_stream_snf, dest_snf, format = "parquet", 
               max_rows_per_file = 3e5,
              #max_open_files=20, #default is 900L
              hive_style = TRUE,
              existing_data_behavior = "overwrite")
```


## Identify inpatients that originated in the ED

NOTE: To identify Inpatient claims that originated in ED: https://resdac.org/articles/how-identify-hospital-claims-emergency-room-visits-medicare-claims-data
In summary, to find ER visits:

Outpatient files:  Revenue Center Codes 0450-0459, 0981
Inpatient files:  Revenue Center Codes 0450-0459, 0981
Although one can assume ER patients found in the inpatient data were admitted to the hospital, one cannot assume ER patients found in the outpatient data were not admitted to the hospital. Because some patients are transferred to a different hospital for admission and some hospitals bill ER and inpatient services separately, determining admission status for those ER visits found in the Outpatient file requires linking to the inpatient data to find evidence of an admission. Please note charges for one ER visit will be found in either the Outpatient claims or the Inpatient claims; a visit will not generate ER charges on both an inpatient claim and an outpatient claim.
need to find people from both outpatient and inpatient files with an ED code, then reconcile

note just because someone has an ED flag, doesn't mean they directly came from ED could be ED to hospital 1 transferred to hospital 2. Should also filter by listed admission source AND de-duplicate (e.g., only count first visit in a certain time frame).
```{r, eval=F}

#which people had an inpatient claim?
# inp_ids <- pq_stream_inp_k %>%
#   dplyr::select(DSYSRTKY) %>%
#     collect() %>%
#   pull(DSYSRTKY) %>%
#   unique()
# saveRDS(inp_ids,'./Data/unique_inpatient_ids_k.rds')

pq_stream_charge_k_inp <- open_dataset("T:/parquet/inp_k_chg/", format = "parquet" ) 


inp_ids <- readRDS('./Data/unique_inpatient_ids_k.rds') #66 mB


inp_ed_codes <- pq_stream_charge_k_inp %>%
  dplyr::select(DSYSRTKY,REV_CNTR) %>%
  filter( (REV_CNTR >='0450' & REV_CNTR<= '0459')| REV_CNTR=='0981' ) %>%
  collect()

#Note this is CSV, not parquet
csv_stream_out_k <- open_dataset("T:/out/charge_k/", format = "csv" , schema=sch_outp_rev ) %>%
  dplyr::select(DSYSRTKY,REV_CNTR) %>%
  filter( DSYSRTKY %in% inp_ids & (REV_CNTR >='0450' & REV_CNTR<= '0459')| REV_CNTR=='0981' ) %>%
  collect()

inp_ed_codes <- inp_ed_codes %>%
  mutate(DSYSRTKY=as.character(DSYSRTKY))

csv_stream_out_k <- csv_stream_out_k %>%
  mutate(DSYSRTKY=as.character(DSYSRTKY))

#people who are inpatients and have an ED code from either outpatient or inpatient file (note match by date; this is crude approach) 
 bind_rows(csv_stream_out_k,inp_ed_codes) %>%
 saveRDS('./Data/ed_inpatients.rds')
```

```{r}

```

